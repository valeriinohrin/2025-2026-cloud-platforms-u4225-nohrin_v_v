# Лабораторная работа №4 — Разработка инфраструктуры MVP AI приложения

Университет: Университет ИТМО 
Факультет: ФТМИ 
Дисциплина: Облачные платформы как основа технологического 
Группа: U4225 
Год: 2025/2026 
Студент: Нохрин Валерий Витальевич 
GitHub: valeriinohrin 
Репозиторий: 2025-2026-cloud-platforms-u4225-nohrin_v_v 
Дата начала: 01.12.2025 
Дата завершения: 01.12.2025

## Цель работы
Создать прототип AI-приложения с базовой функциональностью – создать три варианта архитектуры облачного приложения на разных этапах развития продукта: MVP, тестирование партнёрами, продовая версия с высокой нагрузкой, и необходимо объяснить выбор сервисов и рассчитать примерные затраты на каждый этап.

## Описание приложения

Приложение — сервис подбора имён с использованием модели, которая учитывает созвучие с фамилией и отчеством, стиль имени и другие характеристики.  
Backend работает в облаке, хранение данных также полностью облачное.  
Нужно построить архитектуру так, чтобы она могла развиваться вместе с продуктом.

## Ход работы

# Сценарий 1 — MVP
На этом этапе задача проста: запустить минимально работающий сервис и проверить интерес пользователей. Нужны только самые базовые компоненты, которые не требуют администрирования.

Используется Cloud Run для backend, Firestore для хранения данных и Cloud Storage для файлов. Вся логика работает в одном сервисе. Стоимость крайне низкая, инфраструктура простая.

Диаграмма MVP:
![scenario1](./scenario_1.png)


# Сценарий 2 — Тестирование партнёрами

На этом этапе нагрузка становится выше. Нужен отдельный ML-сервис, чтобы можно было обновлять модель независимо от backend. Также появляется необходимость собирать аналитику запросов.

Добавляется отдельная среда, расширяется логирование, используется BigQuery для анализа поведения пользователей. Cloud Run масштабируется динамически. Инфраструктура становится гибче, но остаётся serverless.

Диаграмма:
![scenario2](./scenario_2.png)

# Сценарий 3 — Продовая версия

Продовая архитектура должна быть стабильной и надёжной.  
Появляется глобальный балансировщик, приватная сеть, отдельный ML-endpoint на Vertex AI или GPU-виртуалке. Данные разделяются на несколько уровней: активные данные, бэкапы, служебные файлы.

Применяется мониторинг, система уведомлений, контроль SLA.  
Все компоненты размещаются в отдельных сервисах, что позволяет масштабировать их независимо.

Диаграмма:
![scenario3](./scenario_3.png)

# Экономическая часть

Ниже — ориентировочные расходы, без лишних терминов, в простом «студенческом» формате.  
Акцент — только на сути и на том, как меняется стоимость от этапа к этапу.

## MVP (примерно 5–12 долларов в месяц)

На MVP используются самые дешёвые ресурсы, которые могут простаивать бесплатно.

Cloud Run почти ничего не стоит, если трафик небольшой. Firestore и Storage занимают копейки. Логи и мониторинг — минимальные.  
Весь проект на этом этапе обходится буквально в несколько долларов.

## Тестирование партнёрами (примерно 25–60 долларов в месяц)

Когда появляется внешний трафик, уже есть постоянные запросы:

- backend работает чаще  
- ML-сервис тоже нагружается  
- данных становится больше  
- логов — тоже больше  

Основная часть расходов — два Cloud Run сервиса и ML-вычисления.  
Стоимость всё ещё умеренная, но заметно выше, чем на MVP.

## Продовая версия (примерно 180–400 долларов в месяц)

Главная статья расходов — ML-вычисления на GPU или Vertex AI endpoint.  
Добавляются ресурсы для стабильности:

- глобальный балансировщик  
- постоянная работа backend  
- monitoring и logging  
- бэкапы и хранение датасетов  

На проде важна не экономия, а предсказуемость и надёжность.  
Поэтому итоговая стоимость гораздо выше, чем на предыдущих этапах.

# Обоснование выбора ресурсов

На MVP не нужны тяжёлые сервисы — главное быстро проверить гипотезу.  
Cloud Run и Firestore дают именно это: быстро, просто и дёшево.

На стадии партнёрского тестирования приходится разделять backend и ML-часть, чтобы не мешать разработке и не ломать основную логику. Появляется аналитика, больше логов, поэтому инфраструктура усложняется.

В продовой версии ключевым становится качество сервиса: предсказуемость времени ответа и стабильность. Поэтому модель выносится на Vertex AI, добавляется балансировщик, приватная сеть и мониторинг.

# Вывод

В работе разработаны три архитектуры облачного приложения для разных этапов развития продукта.  
Каждый этап использует только те ресурсы, которые нужны в данный момент — от минимального и дешёвого MVP до надёжной и масштабируемой продовой версии.

Были также рассчитаны примерные расходы и объяснено, почему архитектура усложняется по мере роста продукта.
